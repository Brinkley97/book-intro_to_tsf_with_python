{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e63f01-296a-449d-9fb3-70aedf7a4b05",
   "metadata": {},
   "source": [
    "# 7.2.2. Multi Layer Perception Model\n",
    "\n",
    "1. See Notion Notes for short-hand notation, explanations, my thoughts, etc.\n",
    "2. BOOKS:\n",
    "    - Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python by Jason Brownlee\n",
    "    - Introduction to TSF with Python - How to Prepare Data and Develop Models to Predict the Future by Jason Brownlee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5754059-f73d-4f20-9cbd-8f27e16cefd7",
   "metadata": {},
   "source": [
    "# Imports + Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd53d4ac-3728-4634-9b56-6a4d9e9ec10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 17:51:59.474021: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce953da-c619-4680-8cc0-0d2ecbc63700",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "PATH_TO_BOOK = 'book-intro_to_tsf_with_python/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7fccdd-aa53-4236-adcd-8993a31a3bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brinkley97/Documents/development/book-intro_to_tsf_with_python/3-timeSeriesAsSupervisedLearning.ipynb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_AS_SML_FILE = BASE + PATH_TO_BOOK + '3-timeSeriesAsSupervisedLearning.ipynb'\n",
    "TS_AS_SML_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9f7a62-e15f-481b-b7dd-29dd97179473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load TS_AS_SML_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a8691f-353a-468b-8d05-d9df240d79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run $TS_AS_SML_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998cf99-ab26-4b18-b031-46aca11a3312",
   "metadata": {},
   "source": [
    "# For Full Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732a2b22-b84a-4d8f-b565-bf22289cc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BASE + PATH_TO_BOOK + 'datasets/daily-min-temperatures.csv'\n",
    "series = pd.read_csv(dataset, header=0, index_col=0)\n",
    "# series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4101ccc-0796-4e17-884b-38e65b429c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = series.values\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65a60cb-7c6b-47d4-a28f-408156d015b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, n_test):\n",
    "    \n",
    "    train_X_y = data[:-n_test]\n",
    "    print(\"train_X_y:\", len(train_X_y), train_X_y)\n",
    "    \n",
    "    test_X_y = data[-n_test:]\n",
    "    print(\"test_X_y:\", len(test_X_y), test_X_y)\n",
    "    \n",
    "    return train_X_y, test_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79fddcd-5aa5-41c4-9d24-47aff832d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_y: 3638 [[20.7]\n",
      " [17.9]\n",
      " [18.8]\n",
      " ...\n",
      " [13.9]\n",
      " [17.2]\n",
      " [14.7]]\n",
      "test_X_y: 12 [[15.4]\n",
      " [13.1]\n",
      " [13.2]\n",
      " [13.9]\n",
      " [10. ]\n",
      " [12.9]\n",
      " [14.6]\n",
      " [14. ]\n",
      " [13.6]\n",
      " [13.5]\n",
      " [15.7]\n",
      " [13. ]]\n"
     ]
    }
   ],
   "source": [
    "n_test = 12\n",
    "train_data, test_data = train_test_split(data, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b73440d-ee9e-41ba-b67c-5824526585bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4ef7d5da-e824-4e68-89dd-4b49cda26b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_uts_sequence_to_sml(uts_observations, prior_observations, forecasting_step):\n",
    "    \"\"\"Splits a given UTS into multiple input rows where each input row has a specified number of timestamps and the output is a single timestamp.\n",
    "    \n",
    "    Parameters:\n",
    "    uts_observations -- 1D np array (of UTS data to transform to SML data with size  b rows/length x 1 dimension)\n",
    "    prior_observations -- py int (of all observations before we get to where we want to start making the predictions)\n",
    "    forecasting_step -- py int (of how far out to forecast, 1 only the next timestamp, 2 the next two timestamps, ... n the next n timestamps)\n",
    "    \n",
    "    Return:\n",
    "    agg.values -- np array (of new sml data)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(uts_observations)\n",
    "    cols = list()\n",
    "    \n",
    "    lag_col_names = []\n",
    "    count_lag = 0\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for prior_observation in range(prior_observations, 0, -1):\n",
    "        # print(\"prior_observation: \", prior_observation)\n",
    "        cols.append(df.shift(prior_observation))\n",
    "        new_col_name = \"t-\" + str(prior_observation)\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, forecasting_step):\n",
    "        cols.append(df.shift(-i))\n",
    "        new_col_name = \"t\"\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "        # put it all together\n",
    "        uts_sml_df = pd.concat(cols, axis=1) \n",
    "        uts_sml_df.columns=[lag_col_names]\n",
    "        # drop rows with NaN values\n",
    "        uts_sml_df.dropna(inplace=True)\n",
    "    \n",
    "    # print(uts_sml_df)\n",
    "    \n",
    "    # colums to use to make prediction for last col\n",
    "    X_train = uts_sml_df.iloc[:, 0: -1]\n",
    "    \n",
    "    # last column\n",
    "    y_train = uts_sml_df.iloc[:, [-1]]\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2aa674a1-f029-4930-8540-02d0c818a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_observations, forecasting_step = [24, 1]\n",
    "X_train_df, y_train_df = convert_uts_sequence_to_sml(train_data, prior_observations, forecasting_step) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b91dbdaa-22a3-41fc-be2a-393b680da2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t-24</th>\n",
       "      <th>t-23</th>\n",
       "      <th>t-22</th>\n",
       "      <th>t-21</th>\n",
       "      <th>t-20</th>\n",
       "      <th>t-19</th>\n",
       "      <th>t-18</th>\n",
       "      <th>t-17</th>\n",
       "      <th>t-16</th>\n",
       "      <th>t-15</th>\n",
       "      <th>...</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>...</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>...</td>\n",
       "      <td>20.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>24.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>16.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>17.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>15.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>...</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>12.2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>...</td>\n",
       "      <td>20.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>10.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.2</td>\n",
       "      <td>...</td>\n",
       "      <td>19.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>11.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>...</td>\n",
       "      <td>15.5</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>13.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>...</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3614 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      t-24  t-23  t-22  t-21  t-20  t-19  t-18  t-17  t-16  t-15  ...  t-10  \\\n",
       "24    20.7  17.9  18.8  14.6  15.8  15.8  15.8  17.4  21.8  20.0  ...  25.0   \n",
       "25    17.9  18.8  14.6  15.8  15.8  15.8  17.4  21.8  20.0  16.2  ...  20.7   \n",
       "26    18.8  14.6  15.8  15.8  15.8  17.4  21.8  20.0  16.2  13.3  ...  20.6   \n",
       "27    14.6  15.8  15.8  15.8  17.4  21.8  20.0  16.2  13.3  16.7  ...  24.8   \n",
       "28    15.8  15.8  15.8  17.4  21.8  20.0  16.2  13.3  16.7  21.5  ...  17.7   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "3633  15.0  12.2  10.5  11.1  13.0  12.9   8.8  14.7  14.7  12.7  ...  20.5   \n",
       "3634  12.2  10.5  11.1  13.0  12.9   8.8  14.7  14.7  12.7  13.3  ...  20.2   \n",
       "3635  10.5  11.1  13.0  12.9   8.8  14.7  14.7  12.7  13.3  13.2  ...  19.4   \n",
       "3636  11.1  13.0  12.9   8.8  14.7  14.7  12.7  13.3  13.2  16.2  ...  15.5   \n",
       "3637  13.0  12.9   8.8  14.7  14.7  12.7  13.3  13.2  16.2  17.3  ...  14.1   \n",
       "\n",
       "       t-9   t-8   t-7   t-6   t-5   t-4   t-3   t-2   t-1  \n",
       "24    20.7  20.6  24.8  17.7  15.5  18.2  12.1  14.4  16.0  \n",
       "25    20.6  24.8  17.7  15.5  18.2  12.1  14.4  16.0  16.5  \n",
       "26    24.8  17.7  15.5  18.2  12.1  14.4  16.0  16.5  18.7  \n",
       "27    17.7  15.5  18.2  12.1  14.4  16.0  16.5  18.7  19.4  \n",
       "28    15.5  18.2  12.1  14.4  16.0  16.5  18.7  19.4  17.2  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "3633  20.2  19.4  15.5  14.1  11.0  11.1  14.0  11.4  12.5  \n",
       "3634  19.4  15.5  14.1  11.0  11.1  14.0  11.4  12.5  13.4  \n",
       "3635  15.5  14.1  11.0  11.1  14.0  11.4  12.5  13.4  13.6  \n",
       "3636  14.1  11.0  11.1  14.0  11.4  12.5  13.4  13.6  13.9  \n",
       "3637  11.0  11.1  14.0  11.4  12.5  13.4  13.6  13.9  17.2  \n",
       "\n",
       "[3614 rows x 24 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4cf1eeda-8449-4b7f-8610-b55bd7085749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3614 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         t\n",
       "24    16.5\n",
       "25    18.7\n",
       "26    19.4\n",
       "27    17.2\n",
       "28    15.5\n",
       "...    ...\n",
       "3633  13.4\n",
       "3634  13.6\n",
       "3635  13.9\n",
       "3636  17.2\n",
       "3637  14.7\n",
       "\n",
       "[3614 rows x 1 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2357cdb2-b053-4039-8baa-ac90ce7d7680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[20.7 17.9 18.8 ... 18.2 12.1 14.4]\n",
      " [17.9 18.8 14.6 ... 12.1 14.4 16. ]\n",
      " [18.8 14.6 15.8 ... 14.4 16.  16.5]\n",
      " ...\n",
      " [10.5 11.1 13.  ... 11.4 12.5 13.4]\n",
      " [11.1 13.  12.9 ... 12.5 13.4 13.6]\n",
      " [13.  12.9  8.8 ... 13.4 13.6 13.9]]\n",
      "y_train [16.5 18.7 19.4 ... 13.9 17.2 14.7]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_df.values[:, :-1]\n",
    "print(\"X_train:\", X_train)\n",
    "y_train = y_train_df.values[:, -1] \n",
    "print(\"y_train\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da098a26-e54d-4380-a89d-b50062591c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model \n",
    "def mlp_model_fit(X_train, y_train, n_nodes, n_epochs, n_batch, prior_observations): \n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "    sml_data -- \n",
    "    \n",
    "    \"\"\"\n",
    "    # define model\n",
    "    model = Sequential() \n",
    "    model.add(Dense(n_nodes, activation='relu' , input_dim=prior_observations)) \n",
    "    model.add(Dense(1)) \n",
    "    model.compile(loss='mse' , optimizer='adam') \n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train, y_train, epochs=n_epochs, batch_size=n_batch, verbose=0) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edd124fe-f3f6-46f4-a53b-557e5ae6aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_nodes, n_epochs, n_batch = [500, 100, 100] \n",
    "# print(n_epochs)\n",
    "# model = mlp_model_fit(converted_uts_to_sml, n_nodes, n_epochs, n_batch, prior_observations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6d103-0507-4f2e-986d-6caade15342e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d487b64-4a94-401c-a736-eea3c770579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    # print(\"ACTUAL = \", actual)\n",
    "    # print(\"PREDICTED = \", predicted)\n",
    "    return sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2be572bd-5100-492d-b2b9-14b8273afe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast with a pre-fit model \n",
    "def model_predict(model, history, n_input): \n",
    "\n",
    "    x_input = np.array(history[-n_input:]).reshape(1, n_input) \n",
    "\n",
    "    # forecast \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "\n",
    "    \n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c76a73a-37e8-4c4c-ad82-663431a5570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk-forward validation for univariate data \n",
    "def walk_forward_validation(test_data, model, history, prior_observations, predictions): \n",
    "\n",
    "    # step over each time-step in the test set \n",
    "    for i in range(len(test_data)): \n",
    "        # print(history)\n",
    "        # fit model and make forecast for history \n",
    "        yhat = model_predict(model, history, prior_observations) \n",
    "        # print(yhat)\n",
    "        \n",
    "        # store forecast in list of predictions \n",
    "        predictions.append(yhat)\n",
    "        # print(i, predictions)\n",
    "        \n",
    "        # add actual observation to history for the next loop \n",
    "        # print(test_data[i])\n",
    "        history.append(test_data[i])\n",
    "    # print(predictions)\n",
    "    # estimate prediction error \n",
    "    error = measure_rmse(test_data, predictions) \n",
    "    # print('> %.3f' % error) \n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93889736-96f2-4f61-a46b-95e9df5199b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk_forward_validation(train_data, test_data, model, prior_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47526d01-8610-4dbf-8e53-a65dd1396752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat evaluation of a config \n",
    "def repeat_evaluate(X_train, y_train, test_data, n_test, n_nodes, n_epochs, n_batch, n_repeats, prior_observations):\n",
    "\n",
    "    store_scores = []\n",
    "\n",
    "    for i in range(n_repeats):\n",
    "        print(i)\n",
    "        predictions = list()\n",
    "        model = mlp_model_fit(X_train, y_train, n_nodes, n_epochs, n_batch, prior_observations) \n",
    " \n",
    "    \n",
    "        history = [x for x in train_data]\n",
    "        \n",
    "        score = walk_forward_validation(test_data, model, history, prior_observations, predictions)\n",
    "        print(\"score is : \", score, \"for index\", i)\n",
    "        store_scores.append(score)\n",
    "        print()\n",
    "        \n",
    "    return store_scores\n",
    "    # return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "074ed4bc-341a-44d3-a929-6604ff19d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes, n_epochs, n_batch = [12, 500, 100] \n",
    "n_repeats = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f80ef9b2-70cc-4929-aadc-c4e233552877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 17:52:06.368771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is :  1.6718007487223239 for index 0\n",
      "\n",
      "1\n",
      "score is :  1.6890238428438575 for index 1\n",
      "\n",
      "2\n",
      "score is :  1.7217974025691891 for index 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = repeat_evaluate(X_train, y_train, test_data, n_test, n_nodes, n_epochs, n_batch, n_repeats, prior_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26939aa4-2b4a-4bae-8060-3e7fc9fc1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize model performance\n",
    "# def summarize_scores(name, scores): \n",
    "#     # print a summary\n",
    "#     scores_m, score_std = mean(scores), std(scores)\n",
    "#     print(' %s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std)) \n",
    "    \n",
    "    # box and whisker plot \n",
    "    # pyplot.boxplot(scores)\n",
    "    # pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8e06de3-c2d6-41a9-9b51-d9fcb00aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_scores('mlp' , scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42b2dbdb-e180-4cf8-a18c-bbbfbe44878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df41ce63-e34c-4c9d-ac82-45d3d461c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = [24, 500, 100, 100] \n",
    "# model = model_fit(train, cfg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "811441c6-1d10-4e1f-aa15-fa1bc7fa8f2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # define config\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# config = [24, 500, 100, 100] \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# # grid search \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# scores = repeat_evaluate(data, config, n_test)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m scores \u001b[38;5;241m=\u001b[39m repeat_evaluate(\u001b[43mtraining_data\u001b[49m, n_test, model, prior_observations, test_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# # define config\n",
    "# config = [24, 500, 100, 100] \n",
    "\n",
    "# # grid search \n",
    "# scores = repeat_evaluate(data, config, n_test)\n",
    "scores = repeat_evaluate(training_data, n_test, model, prior_observations, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4045f-c50b-4cec-8767-7fd0cdfd0a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749de8d6-3edb-49c1-8aaf-da63fb5e4fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

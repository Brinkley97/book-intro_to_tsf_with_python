{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e63f01-296a-449d-9fb3-70aedf7a4b05",
   "metadata": {},
   "source": [
    "# 7.2.2. Multi Layer Perception Model\n",
    "\n",
    "1. See Notion Notes for short-hand notation, explanations, my thoughts, etc.\n",
    "2. BOOKS:\n",
    "    - Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python by Jason Brownlee\n",
    "    - Introduction to TSF with Python - How to Prepare Data and Develop Models to Predict the Future by Jason Brownlee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5754059-f73d-4f20-9cbd-8f27e16cefd7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc69620c-608f-4d1d-9540-8374072e0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eccd41c-3d0b-4942-ad00-3a42f58ffb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 07:12:17.465374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np \n",
    "from math import sqrt \n",
    "from numpy import array \n",
    "from numpy import mean \n",
    "from numpy import std \n",
    "from pandas import DataFrame \n",
    "from pandas import concat \n",
    "from pandas import read_csv \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce953da-c619-4680-8cc0-0d2ecbc63700",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "PATH_TO_BOOK = 'book-intro_to_tsf_with_python/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd7fccdd-aa53-4236-adcd-8993a31a3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS_AS_SML_FILE = BASE + PATH_TO_BOOK + '3-timeSeriesAsSupervisedLearning.ipynb'\n",
    "# TS_AS_SML_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9f7a62-e15f-481b-b7dd-29dd97179473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load TS_AS_SML_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a8691f-353a-468b-8d05-d9df240d79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run $TS_AS_SML_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f55da2-5957-4883-bd4c-1a5ca8ec390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# series = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# n_steps = 3\n",
    "# convert_uts_sequence_to_sml(series, n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc48fdda-7153-427e-a8e5-a99f3827a5f4",
   "metadata": {},
   "source": [
    "# For Single Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52789a8f-7178-4882-b3ed-0a3cc86fd1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(100, activation='relu' , input_dim=n_steps))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(optimizer='adam' , loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f777f37b-14e0-4a2c-98f3-72cb412c8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model \n",
    "# model.fit(X, y, epochs=2000, verbose=0) \n",
    "# # demonstrate prediction \n",
    "# x_input = array([70, 80, 90])\n",
    "# x_input = x_input.reshape((1, n_steps)) \n",
    "# yhat = model.predict(x_input, verbose=0)\n",
    "# print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998cf99-ab26-4b18-b031-46aca11a3312",
   "metadata": {},
   "source": [
    "# For Full Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f65a60cb-7c6b-47d4-a28f-408156d015b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets \n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef7d5da-e824-4e68-89dd-4b49cda26b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "    \n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        \n",
    "        # put it all together\n",
    "        agg = concat(cols, axis=1) \n",
    "        \n",
    "        # drop rows with NaN values\n",
    "        agg.dropna(inplace=True)\n",
    "    \n",
    "    return agg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6d103-0507-4f2e-986d-6caade15342e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d487b64-4a94-401c-a736-eea3c770579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    # print(\"ACTUAL = \", actual)\n",
    "    print(\"PREDICTED = \", predicted)\n",
    "    return sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da098a26-e54d-4380-a89d-b50062591c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model \n",
    "def model_fit(train, config): \n",
    "    # unpack config \n",
    "    n_input, n_nodes, n_epochs, n_batch = config \n",
    "    # prepare data \n",
    "    data = series_to_supervised(train, n_input) \n",
    "    print(\"data: \", data)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1] \n",
    "    # define model\n",
    "    model = Sequential() \n",
    "    model.add(Dense(n_nodes, activation='relu' , input_dim=n_input)) \n",
    "    model.add(Dense(1)) \n",
    "    model.compile(loss='mse' , optimizer='adam' ) \n",
    "    \n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0) \n",
    "    print()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2be572bd-5100-492d-b2b9-14b8273afe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast with a pre-fit model \n",
    "def model_predict(model, history, config): \n",
    "    # unpack config \n",
    "    n_input, _, _, _ = config \n",
    "    # print(n_input)\n",
    "    # prepare data \n",
    "    # print(history)\n",
    "    x_input = array(history[-n_input:]).reshape(1, n_input) \n",
    "    # print(\"x_input =\", x_input)\n",
    "    \n",
    "    # forecast \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "    # print(yhat)\n",
    "    \n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c76a73a-37e8-4c4c-ad82-663431a5570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk-forward validation for univariate data \n",
    "def walk_forward_validation(data, n_test, cfg): \n",
    "    predictions = list()\n",
    "    \n",
    "    # split dataset \n",
    "    train, test = train_test_split(data, n_test) \n",
    "    print(train)\n",
    "    # print(test)\n",
    "    # fit model \n",
    "    model = model_fit(train, cfg) \n",
    "    # print(model)\n",
    "    \n",
    "    # seed history with training dataset \n",
    "    history = [x for x in train]\n",
    "    # print(history)\n",
    "    \n",
    "    # step over each time-step in the test set \n",
    "    for i in range(len(test)): \n",
    "        # print(history)\n",
    "        # fit model and make forecast for history \n",
    "        yhat = model_predict(model, history, cfg) \n",
    "        # print(yhat)\n",
    "        \n",
    "        # store forecast in list of predictions \n",
    "        predictions.append(yhat) \n",
    "        # print(i, predictions)\n",
    "        \n",
    "        # add actual observation to history for the next loop \n",
    "        # print(test[i])\n",
    "        history.append(test[i])\n",
    "        # print()\n",
    "    # estimate prediction error \n",
    "    error = measure_rmse(test, predictions) \n",
    "    print('> %.3f' % error) \n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47526d01-8610-4dbf-8e53-a65dd1396752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat evaluation of a config \n",
    "def repeat_evaluate(data, config, n_test, n_repeats=3): \n",
    "    # print(data)\n",
    "    # fit and evaluate the model n times \n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "    print(scores)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26939aa4-2b4a-4bae-8060-3e7fc9fc1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model performance\n",
    "def summarize_scores(name, scores): \n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print(' %s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std)) \n",
    "    \n",
    "    # box and whisker plot \n",
    "    # pyplot.boxplot(scores)\n",
    "    # pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59e2dc7b-de72-4193-aa26-4f99c597110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BASE + PATH_TO_BOOK + 'datasets/daily-min-temperatures.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3aaa5bc1-2dff-4fd5-afb9-314322d0f1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20.7]\n",
      " [17.9]\n",
      " [18.8]\n",
      " ...\n",
      " [13.9]\n",
      " [17.2]\n",
      " [14.7]]\n",
      "data:  [[20.7 17.9 18.8 ... 14.4 16.  16.5]\n",
      " [17.9 18.8 14.6 ... 16.  16.5 18.7]\n",
      " [18.8 14.6 15.8 ... 16.5 18.7 19.4]\n",
      " ...\n",
      " [10.5 11.1 13.  ... 13.4 13.6 13.9]\n",
      " [11.1 13.  12.9 ... 13.6 13.9 17.2]\n",
      " [13.  12.9  8.8 ... 13.9 17.2 14.7]]\n",
      "\n",
      "PREDICTED =  [array([14.721925], dtype=float32), array([15.425089], dtype=float32), array([13.992274], dtype=float32), array([14.4009695], dtype=float32), array([14.915344], dtype=float32), array([12.355914], dtype=float32), array([14.662391], dtype=float32), array([14.491263], dtype=float32), array([14.227349], dtype=float32), array([14.057744], dtype=float32), array([14.36324], dtype=float32), array([15.278363], dtype=float32)]\n",
      "> 1.806\n",
      "[[20.7]\n",
      " [17.9]\n",
      " [18.8]\n",
      " ...\n",
      " [13.9]\n",
      " [17.2]\n",
      " [14.7]]\n",
      "data:  [[20.7 17.9 18.8 ... 14.4 16.  16.5]\n",
      " [17.9 18.8 14.6 ... 16.  16.5 18.7]\n",
      " [18.8 14.6 15.8 ... 16.5 18.7 19.4]\n",
      " ...\n",
      " [10.5 11.1 13.  ... 13.4 13.6 13.9]\n",
      " [11.1 13.  12.9 ... 13.6 13.9 17.2]\n",
      " [13.  12.9  8.8 ... 13.9 17.2 14.7]]\n",
      "\n",
      "PREDICTED =  [array([13.113655], dtype=float32), array([13.830278], dtype=float32), array([12.466761], dtype=float32), array([12.52532], dtype=float32), array([13.209597], dtype=float32), array([10.689051], dtype=float32), array([13.329743], dtype=float32), array([13.190555], dtype=float32), array([12.469975], dtype=float32), array([12.605876], dtype=float32), array([12.477134], dtype=float32), array([13.614351], dtype=float32)]\n",
      "> 1.791\n",
      "[[20.7]\n",
      " [17.9]\n",
      " [18.8]\n",
      " ...\n",
      " [13.9]\n",
      " [17.2]\n",
      " [14.7]]\n",
      "data:  [[20.7 17.9 18.8 ... 14.4 16.  16.5]\n",
      " [17.9 18.8 14.6 ... 16.  16.5 18.7]\n",
      " [18.8 14.6 15.8 ... 16.5 18.7 19.4]\n",
      " ...\n",
      " [10.5 11.1 13.  ... 13.4 13.6 13.9]\n",
      " [11.1 13.  12.9 ... 13.6 13.9 17.2]\n",
      " [13.  12.9  8.8 ... 13.9 17.2 14.7]]\n",
      "\n",
      "PREDICTED =  [array([14.542862], dtype=float32), array([15.416682], dtype=float32), array([14.018441], dtype=float32), array([13.684023], dtype=float32), array([14.594576], dtype=float32), array([12.11777], dtype=float32), array([14.117944], dtype=float32), array([14.856952], dtype=float32), array([14.491416], dtype=float32), array([14.265941], dtype=float32), array([14.230194], dtype=float32), array([15.383575], dtype=float32)]\n",
      "> 1.797\n",
      "[1.8057518105673087, 1.7908874251139106, 1.7965243914117826]\n"
     ]
    }
   ],
   "source": [
    "series = read_csv(dataset, header=0, index_col=0)\n",
    "data = series.values\n",
    "# data split \n",
    "n_test = 12 \n",
    "\n",
    "# define config\n",
    "config = [24, 500, 100, 100] \n",
    "# grid search \n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores \n",
    "# summarize_scores('mlp' , scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811441c6-1d10-4e1f-aa15-fa1bc7fa8f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4045f-c50b-4cec-8767-7fd0cdfd0a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

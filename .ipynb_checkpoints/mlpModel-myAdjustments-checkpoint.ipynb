{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e63f01-296a-449d-9fb3-70aedf7a4b05",
   "metadata": {},
   "source": [
    "# 7.2.2. Multi Layer Perception Model\n",
    "\n",
    "1. See Notion Notes for short-hand notation, explanations, my thoughts, etc.\n",
    "2. BOOKS:\n",
    "    - Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python by Jason Brownlee\n",
    "    - Introduction to TSF with Python - How to Prepare Data and Develop Models to Predict the Future by Jason Brownlee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5754059-f73d-4f20-9cbd-8f27e16cefd7",
   "metadata": {},
   "source": [
    "# Imports + Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd53d4ac-3728-4634-9b56-6a4d9e9ec10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 08:00:21.981213: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce953da-c619-4680-8cc0-0d2ecbc63700",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/Users/brinkley97/Documents/development/'\n",
    "PATH_TO_BOOK = 'book-intro_to_tsf_with_python/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7fccdd-aa53-4236-adcd-8993a31a3bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brinkley97/Documents/development/book-intro_to_tsf_with_python/3-timeSeriesAsSupervisedLearning.ipynb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_AS_SML_FILE = BASE + PATH_TO_BOOK + '3-timeSeriesAsSupervisedLearning.ipynb'\n",
    "TS_AS_SML_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9f7a62-e15f-481b-b7dd-29dd97179473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load TS_AS_SML_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a8691f-353a-468b-8d05-d9df240d79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run $TS_AS_SML_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998cf99-ab26-4b18-b031-46aca11a3312",
   "metadata": {},
   "source": [
    "# For Full Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732a2b22-b84a-4d8f-b565-bf22289cc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BASE + PATH_TO_BOOK + 'datasets/daily-min-temperatures.csv'\n",
    "series = pd.read_csv(dataset, header=0, index_col=0)\n",
    "# series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4101ccc-0796-4e17-884b-38e65b429c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = series.values\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b565f-1212-4572-92d4-de225c5493c3",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65a60cb-7c6b-47d4-a28f-408156d015b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets \n",
    "def train_test_split(data, n_test):\n",
    "    \n",
    "    train_X_y = data[:-n_test]\n",
    "    print(\"train_X_y:\", len(train_X_y), train_X_y)\n",
    "    \n",
    "    test_X_y = data[-n_test:]\n",
    "    print(\"test_X_y:\", len(test_X_y), test_X_y)\n",
    "    \n",
    "    return train_X_y, test_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79fddcd-5aa5-41c4-9d24-47aff832d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_y: 3638 [[20.7]\n",
      " [17.9]\n",
      " [18.8]\n",
      " ...\n",
      " [13.9]\n",
      " [17.2]\n",
      " [14.7]]\n",
      "test_X_y: 12 [[15.4]\n",
      " [13.1]\n",
      " [13.2]\n",
      " [13.9]\n",
      " [10. ]\n",
      " [12.9]\n",
      " [14.6]\n",
      " [14. ]\n",
      " [13.6]\n",
      " [13.5]\n",
      " [15.7]\n",
      " [13. ]]\n"
     ]
    }
   ],
   "source": [
    "n_test = 12\n",
    "train_data, test_data = train_test_split(data, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b73440d-ee9e-41ba-b67c-5824526585bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef7d5da-e824-4e68-89dd-4b49cda26b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_uts_sequence_to_sml(uts_observations, prior_observations, forecasting_step):\n",
    "    \"\"\"Splits a given UTS into multiple input rows where each input row has a specified number of timestamps and the output is a single timestamp.\n",
    "    \n",
    "    Parameters:\n",
    "    uts_observations -- 1D np array (of UTS data to transform to SML data with size  b rows/length x 1 dimension)\n",
    "    prior_observations -- py int (of all observations before we get to where we want to start making the predictions)\n",
    "    forecasting_step -- py int (of how far out to forecast, 1 only the next timestamp, 2 the next two timestamps, ... n the next n timestamps)\n",
    "    \n",
    "    Return:\n",
    "    agg.values -- np array (of new sml data)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(uts_observations)\n",
    "    cols = list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for prior_observation in range(prior_observations, 0, -1):\n",
    "        cols.append(df.shift(prior_observation))\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, forecasting_step):\n",
    "        cols.append(df.shift(-i))\n",
    "        \n",
    "        # put it all together\n",
    "        agg = pd.concat(cols, axis=1) \n",
    "        \n",
    "        # drop rows with NaN values\n",
    "        agg.dropna(inplace=True)\n",
    "    # print(agg)\n",
    "    \n",
    "        \n",
    "    X_train = agg.values[:, :-1]\n",
    "    # print(\"X_train:\", X_train)\n",
    "    y_train = agg.values[:, -1] \n",
    "    # print(\"y_train\", y_train)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aa674a1-f029-4930-8540-02d0c818a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_observations, forecasting_step = [24, 1]\n",
    "X_train, y_train = convert_uts_sequence_to_sml(train_data, prior_observations, forecasting_step) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b91dbdaa-22a3-41fc-be2a-393b680da2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.7, 17.9, 18.8, ..., 12.1, 14.4, 16. ],\n",
       "       [17.9, 18.8, 14.6, ..., 14.4, 16. , 16.5],\n",
       "       [18.8, 14.6, 15.8, ..., 16. , 16.5, 18.7],\n",
       "       ...,\n",
       "       [10.5, 11.1, 13. , ..., 12.5, 13.4, 13.6],\n",
       "       [11.1, 13. , 12.9, ..., 13.4, 13.6, 13.9],\n",
       "       [13. , 12.9,  8.8, ..., 13.6, 13.9, 17.2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cf1eeda-8449-4b7f-8610-b55bd7085749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.5, 18.7, 19.4, ..., 13.9, 17.2, 14.7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da098a26-e54d-4380-a89d-b50062591c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model \n",
    "def mlp_model_fit(X_train, y_train, n_nodes, n_epochs, n_batch, prior_observations): \n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "    sml_data -- \n",
    "    \n",
    "    \"\"\"\n",
    "    # define model\n",
    "    model = Sequential() \n",
    "    model.add(Dense(n_nodes, activation='relu' , input_dim=prior_observations)) \n",
    "    model.add(Dense(1)) \n",
    "    model.compile(loss='mse' , optimizer='adam') \n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train, y_train, epochs=n_epochs, batch_size=n_batch, verbose=0) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edd124fe-f3f6-46f4-a53b-557e5ae6aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_nodes, n_epochs, n_batch = [500, 100, 100] \n",
    "# print(n_epochs)\n",
    "# model = mlp_model_fit(converted_uts_to_sml, n_nodes, n_epochs, n_batch, prior_observations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6d103-0507-4f2e-986d-6caade15342e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d487b64-4a94-401c-a736-eea3c770579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    # print(\"ACTUAL = \", actual)\n",
    "    # print(\"PREDICTED = \", predicted)\n",
    "    return sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2be572bd-5100-492d-b2b9-14b8273afe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast with a pre-fit model \n",
    "def model_predict(model, history, n_input): \n",
    "\n",
    "    x_input = np.array(history[-n_input:]).reshape(1, n_input) \n",
    "\n",
    "    # forecast \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "\n",
    "    \n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c76a73a-37e8-4c4c-ad82-663431a5570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk-forward validation for univariate data \n",
    "def walk_forward_validation(test_data, model, history, prior_observations, predictions): \n",
    "\n",
    "    # step over each time-step in the test set \n",
    "    for i in range(len(test_data)): \n",
    "        # print(history)\n",
    "        # fit model and make forecast for history \n",
    "        yhat = model_predict(model, history, prior_observations) \n",
    "        # print(yhat)\n",
    "        \n",
    "        # store forecast in list of predictions \n",
    "        predictions.append(yhat)\n",
    "        # print(i, predictions)\n",
    "        \n",
    "        # add actual observation to history for the next loop \n",
    "        # print(test_data[i])\n",
    "        history.append(test_data[i])\n",
    "    # print(predictions)\n",
    "    # estimate prediction error \n",
    "    error = measure_rmse(test_data, predictions) \n",
    "    # print('> %.3f' % error) \n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93889736-96f2-4f61-a46b-95e9df5199b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk_forward_validation(train_data, test_data, model, prior_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47526d01-8610-4dbf-8e53-a65dd1396752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat evaluation of a config \n",
    "def repeat_evaluate(X_train, y_train, test_data, n_test, n_nodes, n_epochs, n_batch, n_repeats, prior_observations):\n",
    "\n",
    "    store_scores = []\n",
    "\n",
    "    for i in range(n_repeats):\n",
    "        print(i)\n",
    "        predictions = list()\n",
    "        model = mlp_model_fit(X_train, y_train, n_nodes, n_epochs, n_batch, prior_observations) \n",
    " \n",
    "    \n",
    "        history = [x for x in train_data]\n",
    "        \n",
    "        score = walk_forward_validation(test_data, model, history, prior_observations, predictions)\n",
    "        print(\"score is : \", score, \"for index\", i)\n",
    "        store_scores.append(score)\n",
    "        print()\n",
    "        \n",
    "    return store_scores\n",
    "    # return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "074ed4bc-341a-44d3-a929-6604ff19d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes, n_epochs, n_batch = [12, 500, 100] \n",
    "n_repeats = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f80ef9b2-70cc-4929-aadc-c4e233552877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 08:00:24.572465: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is :  1.6789646931988174 for index 0\n",
      "\n",
      "1\n",
      "score is :  1.6332766716933294 for index 1\n",
      "\n",
      "2\n",
      "score is :  1.6562764094657891 for index 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = repeat_evaluate(X_train, y_train, test_data, n_test, n_nodes, n_epochs, n_batch, n_repeats, prior_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26939aa4-2b4a-4bae-8060-3e7fc9fc1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize model performance\n",
    "# def summarize_scores(name, scores): \n",
    "#     # print a summary\n",
    "#     scores_m, score_std = mean(scores), std(scores)\n",
    "#     print(' %s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std)) \n",
    "    \n",
    "    # box and whisker plot \n",
    "    # pyplot.boxplot(scores)\n",
    "    # pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e06de3-c2d6-41a9-9b51-d9fcb00aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_scores('mlp' , scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b2dbdb-e180-4cf8-a18c-bbbfbe44878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41ce63-e34c-4c9d-ac82-45d3d461c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = [24, 500, 100, 100] \n",
    "# model = model_fit(train, cfg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811441c6-1d10-4e1f-aa15-fa1bc7fa8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define config\n",
    "# config = [24, 500, 100, 100] \n",
    "\n",
    "# # grid search \n",
    "# scores = repeat_evaluate(data, config, n_test)\n",
    "scores = repeat_evaluate(training_data, n_test, model, prior_observations, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4045f-c50b-4cec-8767-7fd0cdfd0a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749de8d6-3edb-49c1-8aaf-da63fb5e4fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
